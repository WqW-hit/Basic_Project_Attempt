{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**简单网络搭建**\n",
    "- 下面这段Python代码用于搭建一个简单的全连接网络，并采用随机数字进行十次训练迭代。\n",
    "- 输出内容将会是十次训练过程中的损失函数迭代情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9747\n",
      "Epoch [2/10], Loss: 0.9715\n",
      "Epoch [3/10], Loss: 0.9684\n",
      "Epoch [4/10], Loss: 0.9655\n",
      "Epoch [5/10], Loss: 0.9627\n",
      "Epoch [6/10], Loss: 0.9600\n",
      "Epoch [7/10], Loss: 0.9575\n",
      "Epoch [8/10], Loss: 0.9552\n",
      "Epoch [9/10], Loss: 0.9530\n",
      "Epoch [10/10], Loss: 0.9510\n",
      "The decline situation of loss: [0.9747289419174194, 0.9714683294296265, 0.9683831334114075, 0.965462327003479, 0.9626545906066895, 0.9600154757499695, 0.9575371742248535, 0.9551947712898254, 0.9530034065246582, 0.9509983062744141]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AppGallery\\Anaconda\\envs\\nlp-code\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([64, 5])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn #引入基本的神经网络结构方法\n",
    "import torch.optim as optim #引入优化器/优化算法\n",
    "\n",
    "class SimpleFCN ( nn.Module ):\n",
    "    def __init__(self):\n",
    "        super( SimpleFCN , self ).__init__()\n",
    "        self.fc1 = nn.Linear( 5 , 20 )\n",
    "        self.fc2 = nn.Linear( 20 , 50 )\n",
    "        self.fc3 = nn.Linear( 50 , 30 )\n",
    "        self.fc4 = nn.Linear( 30 , 10 )\n",
    "        self.fc5 = nn.Linear( 10 , 1 )\n",
    "    def forward( self , x ):\n",
    "        x = torch.relu( self.fc1( x ) )\n",
    "        x = torch.relu( self.fc2( x ) )\n",
    "        x = torch.relu( self.fc3( x ) )\n",
    "        x = torch.relu( self.fc4( x ) )\n",
    "        x = self.fc5( x )\n",
    "        return x\n",
    "\n",
    "model = SimpleFCN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam( model.parameters() , lr= 0.001 )\n",
    "\n",
    "inputs = torch.randn( 64 , 5 )\n",
    "targets = torch.randn( 64 , 5 )\n",
    "\n",
    "loss_history = [ ]\n",
    "for epoch in range( 10 ):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model( inputs )\n",
    "    loss = criterion( outputs , targets )\n",
    "    loss.backward()#反向传播\n",
    "    optimizer.step()#更新权重\n",
    "\n",
    "    loss_history.append( loss.item() )\n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"The decline situation of loss:\" ,  loss_history )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
